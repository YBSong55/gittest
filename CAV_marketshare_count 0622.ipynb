{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAV_marketshare_count.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofgc0RRYMjQE"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "from pandas import json_normalize\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "\n",
        "token='0b8e6db6509f2bf80bda79ad71f5a6b6'\n",
        "AV_token=\"\"\n",
        "\n",
        "\n",
        "def get_project_id(proj_name,i=token):\n",
        "    url = \"https://api.awrcloud.com/api/marketshare/v1/endpoint.php?action=getProjects&token={}\".format(i)\n",
        "    response = requests.get(url).json()\n",
        "    ID_df = json_normalize(response)\n",
        "    proj_id = ID_df.iloc[list(ID_df.iloc[:,1]).index(proj_name),0]\n",
        "    return proj_id\n",
        "#test1 = get_project_id(\"LG.com_UK\")\n",
        "\n",
        "def get_search_engines_id(proj_id,mytoken=token):\n",
        "    url = \"https://api.awrcloud.com/api/marketshare/v1/endpoint.php?action=getSearchEngines&token={}&projectId={}\".format(mytoken,proj_id)\n",
        "    response = requests.get(url).json()\n",
        "    se_df = json_normalize(response)\n",
        "    id = list(se_df['id']).pop()\n",
        "    return id\n",
        "\n",
        "def get_search_engines_name(proj_id,mytoken=token):\n",
        "    url = \"https://api.awrcloud.com/api/marketshare/v1/endpoint.php?action=getSearchEngines&token={}&projectId={}\".format(mytoken,proj_id)\n",
        "    response = requests.get(url).json()\n",
        "    se_df = json_normalize(response)\n",
        "    id = list(se_df['name']).pop()\n",
        "    return id\n",
        "\n",
        "def get_keyword_group_df(proj_id=111, i=token):\n",
        "    url = \"https://api.awrcloud.com/api/marketshare/v1/endpoint.php?action=getKeywordGroups&token={}&projectId={}\".format(i,proj_id)\n",
        "    response = requests.get(url).json()\n",
        "    group_df = json_normalize(response)\n",
        "    return group_df\n",
        "#test2 = getkeyword_group_df(test1)\n",
        "\n",
        "def get_keyword_group_id(group_name, proj_id=111, i=token):\n",
        "    url = \"https://api.awrcloud.com/api/marketshare/v1/endpoint.php?action=getKeywordGroups&token={}&projectId={}\".format(i,proj_id)\n",
        "    response = requests.get(url).json()\n",
        "    group_df = json_normalize(response)\n",
        "    group_id = group_df.iloc[list(group_df.iloc[:,1]).index(group_name),0]\n",
        "    return group_id\n",
        "#test3 = get_keyword_group_id('Brand',test1)\n",
        "\n",
        "def get_metadata_df(proj_id,group_id,obj_date,i=token):\n",
        "    meta_df = pd.DataFrame({})\n",
        "    url = \"https://api.awrcloud.com/api/marketshare/v1/endpoint.php?action=getMetadata&token={}&projectId={}&searchEngineId={}&keywordGroupId={}&startDate={}&stopDate={}&mode=plain\".format(i,proj_id,-1,group_id,obj_date,obj_date)\n",
        "    response = requests.get(url).text\n",
        "    domain_list_raw = response.split('<br/>')\n",
        "    colum_name = domain_list_raw[0].split(',')\n",
        "    columindex=0\n",
        "    for x in colum_name:\n",
        "        flashdata= []\n",
        "        for i in domain_list_raw[1:-1]:\n",
        "            flashdata.append(i.split(',')[columindex])\n",
        "        meta_df[x]=flashdata\n",
        "        columindex = columindex+1\n",
        "    return meta_df\n",
        "#test4 = get_metadata_df(proj_id='111',group_id='33',obj_date='2021-03-29',i=token)\n",
        "#test4 = get_metadata_df(test1,test3,'2021-03-30')\n",
        "\n",
        "def get_domain_urls(proj_id,group_id,obj_date,obj_domain,i=token):\n",
        "    url = \"https://api.awrcloud.com/api/marketshare/v1/endpoint.php?action=getDomainUrls&token={}&projectId={}&searchEngineId=-1&keywordGroupId={}&date={}&domain={}&mode=plain\".format(i,proj_id,group_id,obj_date,obj_domain)\n",
        "    response = requests.get(url).text\n",
        "    url_list_raw = response.split('<br/>')\n",
        "    colum_name = url_list_raw[0].split(',')\n",
        "    url_index=colum_name.index('url')\n",
        "    colum_count=len(colum_name)\n",
        "    url_df = pd.DataFrame(columns = colum_name)\n",
        "    for i in url_list_raw[1:-1]:\n",
        "        flashdata= []\n",
        "        row_list = i.split(',')\n",
        "        flashdata = flashdata+row_list[:url_index]\n",
        "        flashdata.append(','.join(row_list[url_index:url_index-colum_count+1]))\n",
        "        flashdata = flashdata+row_list[url_index-colum_count+1:]\n",
        "        url_df = url_df.append(pd.Series(flashdata,index=url_df.columns), ignore_index=True)\n",
        "    url_df=url_df.astype({'market share':'float','estimated visits':'float','click share':'float'})\n",
        "    return url_df\n",
        "#test5 = get_domain_urls(proj_id='111',group_id='33',obj_date='2021-03-29',obj_domain='lg.com',i=token)\n",
        "\n",
        "\n",
        "def export_top_sites(av_proj_name,start,stop,searchE, num_url=12,token = AV_token):\n",
        "    proj_name = '+'.join(av_proj_name.split())\n",
        "    url = \"https://api.awrcloud.com/v2/get.php?action=topsites_export&project={}&token={}&startDate={}&stopDate={}&pixelPosition=false&topUrls={}&searchEngine={}\".format(proj_name, token, start, stop,num_url,searchE)\n",
        "    response1 = requests.get(url).json()\n",
        "    res_df = json_normalize(response1)\n",
        "    down_url = res_df['details'][0]\n",
        "    return down_url\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv9SKRI68uYX"
      },
      "source": [
        "start_date = \"2021-04-25\"   \n",
        "end_date = \"2021-06-01\" \n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "def date_range(start_date, end_date):\n",
        "    start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    dates = [date.strftime(\"%Y-%m-%d\") for date in pd.date_range(start, periods=(end-start).days+1)]\n",
        "    return dates\n",
        "\n",
        "date_range(start_date,end_date)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khtATLKVpatr"
      },
      "source": [
        "# # 입력부\n",
        "path = '/content/sample_data'\n",
        "date_list = pd.date_range('2021-05-24', periods=7)\n",
        "fail_df= pd.DataFrame({},columns =['f_project','f_group','f_date'])\n",
        "proj_list = ['US_TONE Free','ES_TONE Free','MS_XBOOM']\n",
        "for xxx in proj_list:\n",
        "    proj_id_re = get_project_id(xxx+'_Google')\n",
        "    print(proj_id_re)\n",
        "    group_df = get_keyword_group_df(proj_id_re)\n",
        "    is_general_cate = group_df['name'] == 'General - Category'\n",
        "    group_select = group_df[is_general_cate]\n",
        "    group_select.reset_index(inplace=True)\n",
        "    group_select\n",
        "    group_name = group_select['name']\n",
        "    group_id = group_select['id']\n",
        "    for x in group_id[:]:\n",
        "        all_df = pd.DataFrame({})\n",
        "        count = 0\n",
        "        filename = \"{}_result_{}\".format(xxx,x)\n",
        "        for date in date_list:\n",
        "            select_date = str(date)[:10]\n",
        "            print(select_date)\n",
        "            try:\n",
        "                sub_df= get_metadata_df(proj_id = proj_id_re,group_id = x, obj_date = str(select_date),i=token)\n",
        "                sub_df = sub_df.astype({'urls': 'float'})\n",
        "            except:\n",
        "                flash_data = [xxx, x, select_date]\n",
        "                fail_df = fail_df.append(pd.Series(flash_data, index=fail_df.columns), ignore_index=True)\n",
        "                print(fail_df)\n",
        "                sub_df = pd.DataFrame({})\n",
        "                pass\n",
        "            all_df = pd.concat([all_df,sub_df])\n",
        "        grouped_df = all_df['urls'].groupby(all_df['domain'])\n",
        "        aa = grouped_df.sum()\n",
        "        bb = aa.sort_values(ascending=False)\n",
        "        count=count+1\n",
        "        bb.to_excel('{}.xlsx'.format(filename),index=True)\n",
        "        print(count)\n",
        "    files.download('{}.xlsx'.format(filename))\n",
        "    print(fail_df)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}